{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Parsing masses from Isilo and generating Structured files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import Libraries\n",
    "This cell imports necessary libraries for the notebook. BeautifulSoup is used for parsing HTML content, ElementTree for working with XML data, and other libraries for handling regular expressions and file operations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import BeautifulSoup\n",
    "import xml.etree.ElementTree as ET\n",
    "import xml.dom.minidom\n",
    "import re\n",
    "import os\n",
    "import json\n",
    "from collections import defaultdict"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Using recursive default dicts to have more flexibility"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recursive_defaultdict():\n",
    "    return defaultdict(recursive_defaultdict)\n",
    "\n",
    "def defaultdict_to_dict(d):\n",
    "    if isinstance(d, defaultdict):\n",
    "        # Convert the defaultdict itself to a dict\n",
    "        d = dict(d)\n",
    "        # Recursively apply this conversion\n",
    "        for key, value in d.items():\n",
    "            d[key] = defaultdict_to_dict(value)\n",
    "    return d"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: extract_sections\n",
    "This function reads an HTML file and extracts different sections of the text based on specific HTML tags. It uses BeautifulSoup for parsing HTML and organizes the sections into a dictionary. This is helpful for further processing and analysis of the text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_sections(file_path):\n",
    "    with open(file_path, 'r', encoding='utf-8') as file:\n",
    "        soup = BeautifulSoup(file, 'html.parser')\n",
    "\n",
    "    was_h3 = False\n",
    "    current_mass = ''\n",
    "\n",
    "    masses_raw_text = {}\n",
    "    for element in soup.body.find_all():\n",
    "        if element.get_text() == '\\xa0':\n",
    "            continue\n",
    "        \n",
    "        if element.name == 'h3':\n",
    "            if was_h3 == False:\n",
    "                current_mass = ''\n",
    "            was_h3 = True\n",
    "            current_mass += ' ' + element.get_text()\n",
    "        elif element.name == 'p':\n",
    "            if was_h3 == True:\n",
    "                current_mass = current_mass.strip().replace('\\n', ' ')\n",
    "                masses_raw_text[current_mass] = []\n",
    "            if current_mass != '':\n",
    "                masses_raw_text[current_mass].append(element.get_text())\n",
    "            was_h3 = False\n",
    "\n",
    "    return masses_raw_text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: get_mass_by_sections\n",
    "This function processes the raw text of masses, segregating them into different sections based on predefined criteria. It's used for organizing the text data for further processing, making it easier to work with."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_mass_by_sections(mass_raw_text, sections):\n",
    "    mass_by_section = {}\n",
    "    current_section = ''\n",
    "    for text in mass_raw_text:\n",
    "        text = text.replace('\\n', ' ')\n",
    "        is_section_title = False\n",
    "        for section in sections:\n",
    "            if section in text:\n",
    "                is_section_title = True\n",
    "                current_section = text\n",
    "                mass_by_section[current_section] = []\n",
    "        if not is_section_title and current_section != '':\n",
    "            mass_by_section[current_section].append(text)\n",
    "    \n",
    "    return mass_by_section"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Function: create_json_mass_readings\n",
    "This function is responsible for converting organized mass readings into an JSON format. It creates JSON elements from the given metadata, reading indexes, and mass sections, facilitating the structured representation of data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_json_mass_readings(reading_idxs, mass_by_section, filename):\n",
    "\n",
    "    readings = {}\n",
    "\n",
    "    sections = list(mass_by_section.keys())\n",
    "    \n",
    "    readings_present = []\n",
    "    for idx in reading_idxs:\n",
    "        \n",
    "        data_from_title = sections[idx].split(' - ')\n",
    "        name = data_from_title[0].title()\n",
    "        if name.split(\" \")[0] == \"Leitura\":\n",
    "            name = name.split(\" \")[0].title() + ' ' + name.split(\" \")[1].upper()\n",
    "        reference = \" - \".join(data_from_title[1:])\n",
    "        \n",
    "        if reference == \"\":\n",
    "            reference = None\n",
    "        \n",
    "        section_content = mass_by_section[sections[idx]]\n",
    "\n",
    "        reading_data = {}\n",
    "        reading_type = None\n",
    "\n",
    "        if 'Leitura' in name:\n",
    "            reading_type = \"reading-\" + name.split(\" \")[-1]\n",
    "            if reading_type in readings_present:\n",
    "                readings_present.append('alt-' + reading_type)\n",
    "                reading_type = f\"alt-{reading_type}-{reading_type.count('alt-' + reading_type) + 1}\" \n",
    "            else:\n",
    "                readings_present.append(reading_type)\n",
    "            reading_data[\"reference\"] = reference\n",
    "            base_idx = 0\n",
    "            if section_content[0][0] == \"«\":\n",
    "                reading_data[\"snippet\"] = section_content[base_idx]\n",
    "            else:\n",
    "                base_idx = -1\n",
    "            reading_data[\"announcement\"] = section_content[base_idx+1]\n",
    "            reading_data[\"text\"] = re.sub(r\"(Palavra do Senhor\\.)$\", \"\", section_content[base_idx+2])\n",
    "    \n",
    "        if 'Evangelho' in name:\n",
    "            reading_type = \"gospel\"\n",
    "            reading_data[\"reference\"] = reference\n",
    "            if section_content[0][0] == \"«\":\n",
    "                reading_data[\"snippet\"] = section_content[base_idx]\n",
    "            else:\n",
    "                base_idx = -1\n",
    "            reading_data[\"snippet\"] = section_content[0]\n",
    "            reading_data[\"announcement\"] = section_content[1]\n",
    "            reading_data[\"text\"] = re.sub(r\"(Palavra da salvação\\.)$\", \"\", section_content[2])\n",
    "\n",
    "        if 'Aleluia' in name:\n",
    "            reading_type = \"aleluia\"\n",
    "            reading_data[\"reference\"] = reference\n",
    "            reading_data[\"response\"] = ': '.join(section_content[0].split(': ')[1:])\n",
    "            reading_data[\"text\"] = section_content[1]\n",
    "\n",
    "        if 'Salmo' in name:\n",
    "            reading_type = \"psalm\"\n",
    "            reading_data[\"reference\"] = reference\n",
    "\n",
    "            base_idx = 0\n",
    "            if section_content[0][0] == '(':\n",
    "                reading_data['notice'] = section_content[0]\n",
    "                base_idx = 1\n",
    "            \n",
    "            reading_data[\"response\"] = ': '.join(section_content[0].split(': ')[1:])\n",
    "            \n",
    "            if section_content[base_idx+2].split(' ')[0] == 'Ou:':\n",
    "                reading_data['alt-response'] = ' '.join(section_content[base_idx+2].split(' ')[1:])\n",
    "                if len(section_content[base_idx+3:]) % 3 == 1:\n",
    "                    reading_data['verses'] = section_content[base_idx+4::3]\n",
    "                else:\n",
    "                    reading_data['verses'] = section_content[base_idx+3::3]\n",
    "            else:\n",
    "                reading_data['verses'] = section_content[base_idx+2::3]\n",
    "\n",
    "        if reading_type != None:\n",
    "            readings[reading_type] = reading_data\n",
    "        else:\n",
    "            print(\"Reading type not recognized\")\n",
    "\n",
    "    return readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Possible sections to be found inside the raw data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "possible_sections = [\n",
    "    \"ANTÍFONA DE ENTRADA\",\n",
    "    \"ORAÇÃO COLECTA\",\n",
    "    \"ANTÍFONA DA COMUNHÃO\",\n",
    "    \"ORAÇÃO SOBRE AS OBLATAS\",\n",
    "    \"ORAÇÃO DEPOIS DA COMUNHÃO\",\n",
    "    \"LEITURA I \",\n",
    "    \"SALMO RESPONSORIAL\",\n",
    "    \"ALELUIA\",\n",
    "    \"LEITURA II\",\n",
    "    \"EVANGELHO\"\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Scripts for Parsing Files to JSON"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating advent dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "advent_readings = defaultdict(recursive_defaultdict)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Weeks 1-3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_paths = [\n",
    "    \"../_old/AdvSem01.htm\",\n",
    "    \"../_old/AdvSem02.htm\",\n",
    "    \"../_old/AdvSem03.htm\",\n",
    "]\n",
    "\n",
    "weekdays = [\"1\", \"1\", \"1\", \"2\", \"3\", \"4\", \"5\", \"6\", \"7\"]\n",
    "cycles = [\"A\", \"B\", \"C\"]\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    masses_raw_text = extract_sections(file_path)\n",
    "\n",
    "    for i, key in enumerate(list(masses_raw_text.keys())[1:]):\n",
    "        mass_by_section = get_mass_by_sections(masses_raw_text[key], possible_sections)\n",
    "        sections = list(mass_by_section.keys())\n",
    "\n",
    "        keywords = [\"EVANGELHO\", \"LEITURA\", \"ALELUIA\", \"SALMO\"]\n",
    "        reading_idxs = [i for i, element in enumerate(sections) if any(word in element for word in keywords)]\n",
    "\n",
    "        readings = create_json_mass_readings(reading_idxs, mass_by_section, weekdays[i])\n",
    "        if weekdays[i] == \"1\":\n",
    "            if advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]] == {}:\n",
    "                advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]] = []\n",
    "            # readings['cycle'] = cycles[i]\n",
    "            readings = {**{'cycle': cycles[i]}, **readings}\n",
    "            advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]].append(readings)\n",
    "        else:\n",
    "            advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]] = readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4 (Sundays)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"advent\"\n",
    "\n",
    "file_paths = [\n",
    "    \"../_old/AdvSem04.htm\",\n",
    "]\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    masses_raw_text = extract_sections(file_path)\n",
    "\n",
    "    for i, key in enumerate(list(masses_raw_text.keys())[1:4]):\n",
    "        mass_by_section = get_mass_by_sections(masses_raw_text[key], possible_sections)\n",
    "        sections = list(mass_by_section.keys())\n",
    "\n",
    "        keywords = [\"EVANGELHO\", \"LEITURA\", \"ALELUIA\", \"SALMO\"]\n",
    "        reading_idxs = [i for i, element in enumerate(sections) if any(word in element for word in keywords)]\n",
    "\n",
    "        mass_metadata = {\n",
    "            \"season\": season,\n",
    "            \"week\": file_path[-6:-4],\n",
    "            \"weekday\": weekdays[i],\n",
    "        }\n",
    "\n",
    "        readings = create_json_mass_readings(reading_idxs, mass_by_section, weekdays[i])\n",
    "        \n",
    "        if weekdays[i] == \"1\":\n",
    "            if advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]] == {}:\n",
    "                advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]] = []\n",
    "            readings = {**{'cycle': cycles[i]}, **readings}\n",
    "            advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]].append(readings)\n",
    "        else:\n",
    "            advent_readings[f'week-{file_path[-6:-4]}'][weekdays[i]] = readings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Week 4 (Specific days)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "season = \"advent\"\n",
    "month = \"december\"\n",
    "\n",
    "file_paths = [\n",
    "    \"../_old/AdvSem04.htm\",\n",
    "]\n",
    "\n",
    "days = [str(i) for i in range(17, 25)]\n",
    "\n",
    "for i, file_path in enumerate(file_paths):\n",
    "    masses_raw_text = extract_sections(file_path)\n",
    "\n",
    "    for i, key in enumerate(list(masses_raw_text.keys())[4:]):\n",
    "        mass_by_section = get_mass_by_sections(masses_raw_text[key], possible_sections)\n",
    "        sections = list(mass_by_section.keys())\n",
    "\n",
    "        keywords = [\"EVANGELHO\", \"LEITURA\", \"ALELUIA\", \"SALMO\"]\n",
    "        reading_idxs = [i for i, element in enumerate(sections) if any(word in element for word in keywords)]\n",
    "\n",
    "        mass_metadata = {\n",
    "            \"season\": season,\n",
    "            \"week\": file_path[-6:-4],\n",
    "            \"day\": days[i],\n",
    "            \"month\": month,\n",
    "        }\n",
    "\n",
    "        readings = create_json_mass_readings(reading_idxs, mass_by_section, weekdays[i])\n",
    "        \n",
    "        advent_readings[\"december\"][days[i]] = readings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "advent_readings = defaultdict_to_dict(advent_readings)\n",
    "advent = {'readings': advent_readings}\n",
    "\n",
    "output_file_path = f\"../_new/advent.json\"\n",
    "\n",
    "with open(output_file_path, 'w', encoding='utf-8') as file:\n",
    "    json.dump(advent, file, ensure_ascii=False, indent=4)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
